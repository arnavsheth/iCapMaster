%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% MCMC.m
%
% Copyright (C) 2009 by Arthur Korteweg and Morten Sorensen
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% This program implements the MCMC estimation of the dynamic selection model 
% from the paper "Risk and Return Characteristics of Venture Capital 
% Investments in Entrepreneurial Companies".
% 
% The algorithm estimates the model
% 	v_t = v_(t-1) + rf + delta + beta*rmrf + e_t			(valuation equation)
%   W_t = Z_t * gamma_0 + (v_t - vF_t) * gamma_v + eta_t	(selection equation)
% 
% where e(t) ~ N(0, sigma^2) i.i.d.
% 	  eta(t) ~ N(0,1) i.i.d.
% and e(t) and eta(t) are independent
% 
% vF_t is the log-valuation at the previous financing round.
% 
% Z_t = [1 tau tau^2] where tau is the number of periods since the previous 
% observed valuation (i.e. financing round).
% 
% rf is assumed constant.
%
% For details on the algorithm we refer to the above-mentioned paper.
% 
% Simulated data is loaded from "Simdata.mat", which was generated by the 
% Matlab program "Simdata.m"

clear all
close all

load simdata

G_burn  = 1000;                 % # burn-in cycles of the algorithm
G_est   = 5000;                 % # estimation cycles

% initialize samp, which will contain the draws from the posterior
% p(b, sigma2, gamma, logV | Vobs,rmrf)
samp(1).b       = zeros(2,1);   % 2x1 vector containing [delta; beta]
samp(1).sige2   = 0.1^2;        % variance of e
samp(1).gamma   = zeros(4,1);   % the loadings in the selection equation

% priors for alpha, beta and gamma parameters
pr_s2a  = 2.1;                  % prior sige2 ~ IG(pr_s2a, pr_s2b)
pr_s2b  = 600;                   
b0      = zeros(2,1);           % prior b ~ N(b0, inv(A)*sige2)
A       = eye(2)/10000;            
g0      = zeros(4,1);           % prior gamma ~ N(g0, inv(C))
C       = eye(4)/100;

% Find starting and ending periods for each firm's valuation path
for i = 1:N
    II       = find(logVobs(:,i)>0);  % index of observed valuations
    Tstrt(i) = II(1);           % index to first observed valuation
    Tend(i)  = T;               % simulate all firms until the end of the dataset
end

% Set up X_select = [constant log(V_t)-log(VF) tau tau^2] for selection equation (stacking firms vertically)
% NB: The selection equation is W = X_select * gamma + eta
% Also initialize logVF to contain the log-valuation at previous financing event
X_select = zeros(T,4,N);        % selection variables (4 per firm-month)
logVF    = zeros(T,N);          % log-valuations at previous refinancing
logV     = zeros(T,N);          % initialize matrix that will hold the log-valuations (to be used in Gibbs sampler)
eta      = zeros(T,N);          % initialize matrix with errors in the selection equation (to be used in Gibbs sampler)
tau      = 0;                   % counts the time since the previous financing round
for i = 1:N                 
    for t = Tstrt(i):Tend(i) 
        X_select(t,:,i) = [1 logV(t,i)-logVF(t,i) tau tau^2];                 
        if t < T                                % fill in next period's logVF
            if logVobs(t,i) == -999             
                logVF(t+1,i) = logVF(t,i);      % if valuation unobserved: logVF remains unchanged
                tau = tau + 1;                  % increase time since previous financing round
            else 
                logVF(t+1,i) = logVobs(t,i);    % if valuation observed: logVF for next period contains the newly observed valuation  
                tau = 1;                        % reset time since last refinancing
            end
        end    % if t < T        
    end     % for t
end     % for i


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Start the Gibbs Sampler
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
for g = 1:G_burn+G_est
    
    % Display progression every 100 iterations
    if ~mod(g,100)
        disp(g)
    end
       
    % Step 1) Draw the missing data conditional on previous beta and
    %         residual error variance.
    %         Use Kalman Filter and FFBS. The state-space is:
    %            state: X_{t+1} = X_t + rf + delta + beta*rmrf + e_{t+1}
    %            obs:   X*_t = X_t * D_t
    %                   W_t  = Z_t * gamma_0 + X_t * gamma_v + eta_t
    %         where X_t = ln(V_t) and D_t is a (known) vector of 1's one 0's, depending on
    %         whether V_t is observed in a particular month.
    for i = 1:N     % do each firm separately because e_t's are independent    
        EXtt    = zeros(T,1);           % E(v_t|t) 
        EXfwtt  = zeros(T,1);           % E(v_(t+1) | t)
        VXtt    = zeros(T,1);           % Var(v_t | t) 
        gammav  = samp(g).gamma(2);     % gammav = loading on log(V)-log(VF) in selection equation

        % Step A) Filter Forward to get the mean and variance of v(t|t), stored
        %         in EXtt and VXtt        
        for t = Tstrt(i):Tend(i)
            % A1) The updating step    
            if logVobs(t,i) ~= -999     % if V_t observed i.e. if D_t == 1 
                EX = logVobs(t,i);      % observations are without error
                VX = 0;
            else                        % V_t unobserved: apply filter using W_t as an "observation" of v_t
                e  = gammav * (logV(t,i) - EXfw) + eta(t,i);        % note that this conditional on W (which includes the prior draw for v)
                K  = gammav * VXfw / (1 + gammav*gammav*VXfw);      % compute Kalman gain K
                EX = EXfw + K*e;                                    % E(v_t | t)   = E(v_t | t-1) + K * e
                VX = VXfw - K*gammav*VXfw;                          % Var(v_t | t) = Var(v_t | t-1) * (1 - K*gammav)
            end
                
                
            % A2) The forecasting step
            if t<T
                dt = rf + samp(g).b(1) + samp(g).b(2)*rmrf(t);      % dt = rf + delta + beta*rmrf     
            end
            EXfw        = EX + dt;              % E(v_(t+1) | t) = E(v_t | t) + rf + delta + beta*rmrf
            VXfw        = VX + samp(g).sige2;   % Var(v_(t+1) | t) = Var(v_t | t) + sigma^2
            EXtt(t)     = EX;                   % Keep E(v_t | t) for use in backward sampling step
            EXfwtt(t)   = EXfw;                 % Keep E(v_(t+1) | t)
            VXtt(t)     = VX;                   % Keep Var(v_t | t)
        end % for t

    
        % Step B) Sample Backward: to get a draw from the conditional 
        %         distribution of X
        % first draw the last element of X from its conditional normal:
        Xdraw = EXtt(Tend(i)) + randn * sqrt(VXtt(Tend(i)));    % draw v_T|T
        logV(t,i) = Xdraw;
        % Now draw the rest of the state vector (see Carter & Kohn (1994), p.552), working backwards:
        for t = (Tend(i)-1):-1:Tstrt(i)
            if (VXtt(t) == 0)
                Xdraw = EXtt(t);                    % quicker than the filtering step below, if there is zero variance
            else
                e = Xdraw - EXfwtt(t);                      % difference between draw of v_(t+1)|T and E(v_(t+1)|t)
                K = VXtt(t) / (VXtt(t) + samp(g).sige2);    % compute Kalman gain
                r = EXtt(t) + K * e;                        % E(v_t|T) = E(v_t|t) + K * e
                q = VXtt(t) * (1 - K);                      % Var(v_t|T) = Var(v_t|t) * (1 - K)
                Xdraw = r + sqrt(q) * randn;                % draw v_t|T
            end
            logV(t,i) = Xdraw;
        end % for t
    end % for i
        

    % Step 2) Draw eta, the error term of the selection equation
    for i = 1:N     % do each firm separately because eta(t)'s independent 
        for t = Tstrt(i):Tend(i)
            % update the variables in the selection equation with the new draws of log(V)
            X_select(t,2,i) = logV(t,i) - logVF(t,i);    
            % calculate the truncation bound for drawing the eta's
            bound = -X_select(t,:,i) * samp(g).gamma;
            if logVobs(t,i) ~= -999                             % if V_t observed
                eta(t,i) = randn_lowertrunc(bound, 0, 1);       % truncate eta from below            
            else                                                % if V_t not observed
                eta(t,i) = randn_uppertrunc(bound, 0, 1);       % truncate eta from above            
            end
        end % for t           
    end % for i


    % Step 3) Draw delta, beta and sigma^2 from the posterior distribution 
    % of a Bayesian regression, using Normal-IG priors   
    rV = []; X = [];
    for i = 1:N
        rV = [rV; logV(Tstrt(i)+1:Tend(i),i) - logV(Tstrt(i):Tend(i)-1,i) - rf];    % sample excess returns 
        X = [X; ones(Tend(i)-Tstrt(i),1) rmrf(Tstrt(i):Tend(i)-1)];
    end
    post_XXinv      = inv(X'*X + A);                        % post_XXinv = (X'X + A)^(-1)
    post_bmean      = post_XXinv * (A*b0 + X'*rV);          % posterior b ~ N( post_XXinv * (X'y + A*b0) , sigma2 * post_XXinv )
    e               = rV - X*post_bmean;                    % posterior sigma2 ~ IG(post_s2a, post_s2b)
    post_s2a        = pr_s2a + size(rV,1);                  % post_s2a = pr_s2a + # returns
    S               = e'*e + (post_bmean - b0)'*A*(post_bmean - b0);
    post_s2b        = 1 / ((1/pr_s2b) + S);                 % 1/post_s2b = 1/pr_s2b + e'e + (post_bmean - b0)'*A*(post_bmean - b0)
    samp(g+1).sige2 = 1/gaminv(rand,post_s2a,post_s2b);      % draw from posterior IG
    samp(g+1).b     = mvnrnd(post_bmean, samp(g+1).sige2 * post_XXinv)';   % draw from posterior multivariate normal
     
    
    % Step 4) Draw gamma from the posterior distribution of a Bayesian
    % regression, using a Normal prior (and known variance)
    X = []; y = [];
    for i = 1:N                                             % regress X_select on W
        X = [X; X_select(Tstrt(i)+1:Tend(i),:,i)];          % exclude Tstrt since tau unknown
        y = [y; X_select(Tstrt(i)+1:Tend(i),:,i)*samp(g).gamma + eta(Tstrt(i)+1:Tend(i),i)];    
    end
    post_XXinv      = inv(X'*X + C);                        % post_XXinv = (X'X + C)^(-1)
    post_gammean    = post_XXinv * (C*g0 + X'*y);           % posterior gamma ~ N( post_XXinv * (X'y + C*g0) , post_XXinv )
    samp(g+1).gamma = mvnrnd(post_gammean, post_XXinv)';    % draw from posterior multivariate normal, noting that sigma_eta = 1
    
end  % for g



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Summarize the MCMC output in table format
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
disp(' ')
disp('Summary of MCMC posterior');
disp('b:     mean    s.d.    true value');
x = [samp.b]';
disp([mean(x(G_burn+1:end,:))' std(x(G_burn+1:end,:))' [true_delta; true_beta]]);
disp('sigma: mean    s.d.    true value');
x = sqrt([samp.sige2]);
disp([mean(x(G_burn+1:end)) std(x(G_burn+1:end)) true_sige]);
disp('gamma: mean    s.d.    true value');
x = [samp.gamma]'; 
disp([mean(x(G_burn+1:end,:))' std(x(G_burn+1:end,:))' true_gamma]);


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Plot histograms 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
figure;
title('Posterior Histograms')       % 
subplot(2,2,1); x = [samp.b]'; histplot(x(G_burn+1:end,1),25,true_delta); title('\delta');     
subplot(2,2,2); histplot(x(G_burn+1:end,2),25,true_beta); title('\beta');
subplot(2,2,3); x = sqrt([samp.sige2]); histplot(x(G_burn+1:end),25,true_sige); title('\sigma');

figure;
title('Posterior Histograms')
x = [samp.gamma]; NK = size(x,1);
for i = 1:min(NK,8)
    subplot(ceil(min(NK,8)/2),2,i); 
    histplot(x(i,G_burn+1:end),25,true_gamma(i)); 
    title(['\gamma_' num2str(i)]);
end


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Make trace plots
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
figure;
title('Parameter trace plots')
subplot(2,2,1); x = [samp.b]'; plot(x(:,1)); line([1 G_burn+G_est+1], [true_delta true_delta], 'Color', 'r', 'LineWidth', 2); title('\delta'); v = axis; axis([1 G_burn+G_est+1 v(3:4)]); xlabel('Iteration')
subplot(2,2,2); plot(x(:,2)); line([1 G_burn+G_est+1], [true_beta true_beta], 'Color', 'r', 'LineWidth', 2); title('\beta'); v = axis; axis([1 G_burn+G_est+1 v(3:4)]); xlabel('Iteration')
subplot(2,2,3); plot(sqrt([samp.sige2])); line([1 G_burn+G_est+1], [true_sige true_sige], 'Color', 'r', 'LineWidth', 2); title('\sigma'); v = axis; axis([1 G_burn+G_est+1 v(3:4)]); xlabel('Iteration')

figure;
title('Parameter trace plots');
x = [samp.gamma];
for i = 1:min(NK,8)
    subplot(ceil(min(NK,8)/2),2,i); 
    plot(x(i,:)); 
    v = axis;
    axis([1 G_burn+G_est+1 v(3:4)])
    set(gca,'XTick',0:(G_burn+G_est)/5:G_burn+G_est)
    line([1 G_burn+G_est+1], [true_gamma(i) true_gamma(i)], 'Color', 'r', 'LineWidth', 2);
    title(['\gamma_' num2str(i)]);
end
