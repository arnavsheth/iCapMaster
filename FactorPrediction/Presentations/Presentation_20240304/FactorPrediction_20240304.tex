% compile with XeLaTeX
\documentclass[dvipsnames,mathserif, handout]{beamer}
%\setbeamerfont{title}{size=\tiny}
\setbeamertemplate{footline}[frame number]
\setbeamercolor{footline}{fg=black}
\setbeamerfont{footline}{series=\bfseries}

\usepackage{tikz, babel, ulem}
\usepackage[export]{adjustbox}

\usetheme{Frankfurt}%1
%\usetheme{Darmstadt}%1

\setbeamerfont*{itemize/enumerate body}{size=\fontsize{9}{11}}
\setbeamerfont*{itemize/enumerate subbody}{parent=itemize/enumerate body}
\setbeamerfont*{itemize/enumerate subsubbody}{parent=itemize/enumerate body}

\makeatother

%% for RTL liste
%\makeatletter
%\newcommand{\RTListe}{\raggedleft\rightskip\leftm}
%\newcommand{\leftm}{\@totalleftmargin}
%\makeatother
%
%% RTL frame title
%\setbeamertemplate{frametitle}
%{\vspace*{-1mm}
%  \nointerlineskip
%    \begin{beamercolorbox}[sep=0.3cm,ht=2.2em,wd=\paperwidth]{frametitle}
%        \vbox{}\vskip-2ex%
%        \strut\hskip1ex\insertframetitle\strut
%        \vskip-0.8ex%
%    \end{beamercolorbox}
%}
%% align subsection in toc
%\makeatletter
%\setbeamertemplate{subsection in toc}
%{\leavevmode\rightskip=5ex%
%  \llap{\raise0.1ex\beamer@usesphere{subsection number projected}{bigsphere}\kern1ex}%
%  \inserttocsubsection\par%
%}
%\makeatother
%
%% RTL triangle for itemize
%\setbeamertemplate{itemize item}{\scriptsize\raise1.25pt\hbox{\donotcoloroutermaths$\blacktriangleleft$}} 
%
%%\setbeamertemplate{itemize item}{\rule{4pt}{4pt}}
%
%\defbeamertemplate{enumerate item}{square2}
%{\LR{
%    %
%    \hbox{%
%    \usebeamerfont*{item projected}%
%    \usebeamercolor[bg]{item projected}%
%    \vrule width2.25ex height1.85ex depth.4ex%
%    \hskip-2.25ex%
%    \hbox to2.25ex{%
%      \hfil%
%      {\color{fg}\insertenumlabel}%
%      \hfil}%
%  }%
%}}
%
%\setbeamertemplate{enumerate item}[square2]

%\setbeamertemplate{footline}{} %gets rid of footer completely
\setbeamertemplate{navigation symbols}{}


\titlegraphic { 
\begin{tikzpicture}[overlay,remember picture, opacity=0.1,]
\node[] at (0, 2.9){
    \includegraphics[width=0.63\textwidth]{iCapital_logo_RGB.png}
};\end{tikzpicture}}

%\setbeamertemplate{caption}[numbered]
\setbeamertemplate{caption}{\raggedright\insertcaption\par}

\begin{document}

\rightskip\rightmargin
\title{Asset Level CMAs}
\author{ \Large \textbf{} }
\institute{\large\textbf{}\\
Portfolio Analytics Research Team \\
iCapital Network}
\footnotesize{\date{March 04, 2024 }


\begin{frame}
	\maketitle
\end{frame}

\begin{frame}{Summary}
	\footnotesize \tableofcontents
\end{frame}

\section{Executive Summary}

\begin{frame}{Executive Summary}
	\begin{description}[Strategic Impact]
		\item[Objective] 
		\begin{itemize}
			\item Devise and execute repeatable and scientifically rigorous process for generating asset level CMAs.
		\end{itemize} \pause
		\item[Benefits] 
		\begin{itemize}
			\item Consistency of implementation from start to finish. \pause
			\item Establishment of thought leadership in alternatives and private markets space. \pause
			\item Provide support to home offices and advisors for construction of client portfolios.
		\end{itemize} \pause
		\item[Strategic Impact]
		\begin{itemize}
			\item Efficient allocation of risk across investment opportunities. \pause
			\item iCap-powered return and risk forecasts cement alternatives in the main-stream portfolio construction process.
		\end{itemize}
	\end{description}
\end{frame}

	

\section{Problem Statement}

\begin{frame}{Problem Statement}
	\begin{itemize}
		\item Non-specialist external methodologies behind alternative CMAs are notably ad hoc and inconsistent.
		\begin{itemize}
			\item See, for example, Couts, et al. (2023)\footnote{\tiny Couts, S., A. Gon\c{c}alves, and J. Loudis. 2023. The Subjective Risk and Return Expectations of Institutional Investors. SSRN Abstract ID 4458499.}: 
            		\begin{quote}
            			80\% of differences in CMAs between asset managers and investment consultants are driven by one thing only: their initial estimate of how big the compensation for systematic risk is. 
            		\end{quote} \pause
		\end{itemize}
		\item The firms creating generic CMAs do not generally have iCapital’s expertise in the alternatives space. \pause
		\item Other issues:
		\begin{itemize}
			\item External providers have shown reluctance to put their branded CMAs on our platform.
			\item Clients demand guidance and trust iCapital to apply its domain expertise to produce the relevant forecasts. 
		\end{itemize}
	\end{itemize}
\end{frame}

\section{Framework}

\begin{frame}{Framework for Expected Returns Part 1}
	\begin{figure}[!ht]
	\centering
		\includegraphics[height=100pt]{framework1.pdf}
	\end{figure}
\end{frame}

\begin{frame}{Framework for Expected Returns Part 2}
	\begin{figure}[!ht]
	\centering
		\includegraphics[height=100pt]{framework2.pdf}
	\end{figure}
\end{frame}


\begin{frame}{Framework}
	\begin{itemize}
		\item The use of PCA in asset pricing goes back to a series of papers by Connor and Korajczyk (1986, 1988, 1993).
		\item This methodology has precendent in the recent finance literature. See, for example,  Haddad et al (2020)\footnote{\tiny Haddad, V., S. Kozak, S. Santosh. 2020. Factor Timing. \textit{The Review of Financial Studies}, 33(5):1980–2018.}:
		\begin{figure}[!ht]
			\includegraphics[width=275pt]{Steps_canceled.pdf}
		\end{figure}
	\end{itemize}
\end{frame}

%\begin{frame}{Methodology}
%	Haddad et al, Review of Financial Studies 33(2020): pp.1980-2018 
%	\begin{figure}[!ht]
%		\includegraphics[width=300pt]{Steps_canceled.pdf}
%	\end{figure}
%\end{frame}

\section{Methodology}

%\begin{frame}{Methodology}
%	\begin{itemize}
%		\item 

\begin{frame}{Methodology}
	\begin{itemize}
		\item Use \sout{fifty} fifty-five `anomaly' portfolios from Kozak et al. (2020)\footnote{\tiny Kozak, S., S. Nagel, and S. Santosh. 2020. Shrinking the cross-section. \textit{Journal of Financial Economics} 135:271–92.} that effectively capture market heterogeneity.
		\begin{itemize}
			\item These anomalies are the usual anomalies like Size, Value, ROA, SUE, etc.
		\end{itemize}
		\item Break them into deciles, create long-short portfolios for each anomaly (Decile 10 minus Decile 1).
		\begin{itemize}
			\item For each portfolio, they calculate the market-cap-weighted book-to-market ratio ($bm$) of the underlying stocks.
			\item By finding the difference in log book-to-market of Portfolio 10 minus that of Portfolio 1.
		\end{itemize}
		\item NOTE: This is a placeholder until we sort out data issues relating to `CMAs' (indexes).
	\end{itemize}
\end{frame}

%\begin{frame}{Methodology}
%	\begin{itemize}
%		\item Market-adjust and rescale the data. 
%		\begin{enumerate}
%			\item Calculate regression $\beta$ for each anomaly. 
%			\item Market-adjust returns and predictors by subtracting $\beta \times r_{mkt}$ for returns and $\beta \times bm_{mkt}$ for $bm$ ratios.
%			\item Rescale to equalize the variance of market-adjiusted returns, and $bm$ ratios for each anomaly.
%		\end{enumerate}
%		\item So now they have \sout{50} 55 long-short portfolios.
%	\end{itemize}
%\end{frame}

\begin{frame}{Methodology}
	\begin{itemize}
		\item They conduct a PCA to reduce the \sout{50} 55 long-short portfolios to five PCs that explain roughly 60\% of the variance.
		\begin{figure}[!ht]
		\centering
			\includegraphics[width=250pt]{Table1.pdf}
		\end{figure}
		\item Why five? 
		\begin{enumerate}
			\item Campbell and Thompson (2007)\footnote{\tiny Campbell, J. Y., and S. B. Thompson. 2007. Predicting excess stock returns out of sample: Can anything beat the historical average? \textit{Review of Financial Studies} 21:1509–31.} show that the monthly $R^2$ when predicting the market is around 75bp.
			\item A loose upper-bound on the annual Sharpe is 1, or 8.3\% monthly. 
		\end{enumerate}
		\item If each included PC contributes equally to the $R^2$, the harmonic mean of their contribution to the total variance of returns must be $> \frac{0.75}{8.3} \approx 9\%$.
	\end{itemize}
\end{frame} 

\begin{frame}{Methodology}{Current Progress}
	We extend the Haddad et al. study in the following way:
	\begin{enumerate}
		\item Asset class reduction using PCA/SVD. \pause
		\item Regression analysis of principal components on factors. 
		\begin{itemize}
			\item Store coefficients with HAC-robust standard errors. \pause
		\end{itemize}
		\item Use coefficients to calculate expected returns of factors on factors. \pause
		\item ToDo:
		\begin{enumerate}
			\item Calculate variance-covariance matrix of factors using regression coefficients, historical data, and residuals.
			\begin{itemize}
				\item Assume serial correlation. \pause
			\end{itemize}
			\item Use asset-level factor loadings from G3 to get asset-level CMAs. \pause
			\item Resolve myriad data issues around initial asset-class return history generation.
		\end{enumerate}
	\end{enumerate}
\end{frame}

%\section{Background}
%
%\begin{frame}{Literature}{Factor Models}
%	\begin{itemize}
%		\item The original one-factor model is the CAPM (Treynor (1961, 1962), Sharpe (1964), Lintner (1965) and Mossin (1966)).
%		\item This was followed of course by Fama-French's three-factor (1993), and five-factor (2014) model.
%		\item Between 1961 and the present, several hundred factors have been used to explain market inefficiency, market risk, and more.
%		\begin{itemize}
%			\item This led to the phenomenon commonly termed the `factor zoo', or the numerous factors used to explain stock market returns.
%		\end{itemize}
%	\end{itemize}
%\end{frame}
%
%\begin{frame}{Literature}{Factor Zoo}
%	\begin{itemize}
%		\item What is the `factor zoo'?
%		\begin{itemize}
%			\item First mentioned in Harvey, Liu, and Zhang (2016) following McLean and Pontiff (2015).
%			\item Main issue is the proliferation of factors -- they test 316!
%			\item They find that many of these factors are highly correlated.
%		\end{itemize}
%		\item So dimensionality reduction is highly recommended. This applies to our CMA problem as well.
%		\begin{itemize}
%			\item Envestnet, for example, has 55 asset classes. 
%		\end{itemize}
%	\end{itemize}
%\end{frame}
%
%\begin{frame}{Literature}{PCA}
%	\begin{itemize}
%		\item The use of PCA in asset pricing goes back to a series of papers by Connor and Korajczyk (1986, 1988, 1993).
%		\item More recently, Kozak et al. (2020) have done work on dimensionality reduction of the cross-section of asset returns.
%		\item Several other papers include: Kozak and Nagel (2023), Nadler and Sancetta (2023), and more\footnote{\tiny If you're interested, Fama and Stern (2016) have an interesting conversation on factor calculation using cross-sectional versus time series data.}.
%%		\item More and more techniques have been used for this
%%		\begin{itemize}
%%			\item Related, but unrelated: 
%%		\end{itemize}
%	\end{itemize}
%\end{frame}

%\begin{frame}{Literature}{Limitations}
%	\begin{itemize}
%		\item Most of the literature is used to explain risk premia 

\section{Data}

\begin{frame}{Data}
	\begin{itemize}
		\item We start with the anomaly dataset used in Haddad, Kozak, Santosh (2020) (cited earlier). 
		\item Dataset consists of decile data along 55 equity anomalies.
		\begin{itemize}
			\item These consist of characteristics like size, value, momentum, reversal, etc.
		\end{itemize}
		\item Why this dataset? 
		\begin{itemize}
			\item It is easily accessible, and organized well.
			\item It serves as a good placeholder for CMA data.
			\item It is the same database used in Haddad et al. 
		\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}{Data}{Anomaly Dataset (Subset)}
	\begin{figure}[!ht]
		\includegraphics[width=200pt]{anomaly_definitions_subset.pdf}
		\caption{\footnotesize Start date: 07-01-2004. End date: 2019-12-01. Size: 186 x 54.}
	\end{figure}
\end{frame}

\begin{frame}{Data}{Factor Data}
	\begin{figure}[!ht]
		\includegraphics[width=175pt]{FactorDefinitions.pdf}
		\caption{\footnotesize Start date: 07-01-2004. End date: 2019-12-01. Size: 186 x 13.}
	\end{figure}
\end{frame}

\section{Results}

\begin{frame}{Results\footnote{\tiny Caveat: these results should be used for idea generation and for code placeholders; not taken literally.}}
%	{\tiny Caveat: these results should be used for idea generation and for code plcaeholders; not taken literally.}
	\begin{itemize}
		\item Let's start with the dimensionality reduction for the anomalies dataset.
	\end{itemize}
	\begin{figure}[!ht]
		\includegraphics[width=175pt]{scree_plot.pdf}
		\caption{\footnotesize Scree plot}
	\end{figure}
\end{frame}	

\begin{frame}{Results\footnote{\tiny Caveat: these results should be used for idea generation and for code placeholders; not taken literally.}}
	\begin{figure}[!ht]
		\includegraphics[width=200pt]{explained_variance.pdf}
	\end{figure}
	\begin{itemize}
		\item Roughly 80\% of the variance is explained by 14 principal components. 
	\end{itemize}
\end{frame}	

\begin{frame}{Results\footnote{\tiny Caveat: these results should be used for idea generation and for code placeholders; not taken literally.}}
	\begin{itemize}
		\item Running a OLS regression with HAC-robust standard errors, we get, for Alt Commodities:
	\end{itemize}
	\begin{figure}[!ht]
		\includegraphics[width=250pt]{alt_commodities1.pdf}
	\end{figure}
\end{frame}

\begin{frame}{Results\footnote{\tiny Caveat: these results should be used for idea generation and for code placeholders; not taken literally.}}
	\begin{itemize}
		\item Running a OLS regression with HAC-robust standard errors, we get, for Alt Commodities:
	\end{itemize}
	\begin{figure}[!ht]
		\includegraphics[width=200pt]{alt_commodities2.pdf}
	\end{figure}
\end{frame}

\begin{frame}{Results\footnote{\tiny Caveat: these results should be used for idea generation and for code placeholders; not taken literally.}}
	\begin{itemize}
		\item Perhaps run a stepwise regression instead:
	\end{itemize}
	\begin{figure}[!ht]
		\includegraphics[width=200pt]{stepwise_results_subset.pdf}
	\end{figure}
\end{frame}

\begin{frame}{Results\footnote{\tiny Caveat: these results should be used for idea generation and for code placeholders; not taken literally.}}
	\begin{itemize}
		\item Perhaps run a block bootstrap regression instead:
	\end{itemize}
	\begin{figure}[!ht]
		\includegraphics[width=250pt]{block_bootstrap_alt_commodities.pdf}
	\end{figure}
\end{frame}


	
\begin{frame}{Results}
	\begin{itemize}
		\item We use the results of the original linear regression.
		\item The final next-period expected values for the factors are:
		\begin{figure}[!ht]
		\centering
			\includegraphics[width=100pt]{factor_exp_values.pdf}
		\end{figure}
%		\begin{itemize}
%			\item We reconstruct the original matrix using reverse-SVD.\footnote{\tiny Thanks, Aniket.}.
%			\item Use Frobenius norm-minimization techniques for reconstruction.
%		\end{itemize}
	\end{itemize}
\end{frame} 

\begin{frame}{Future Research}
	\begin{itemize}
		\item Generate variance-covariance matrices using the PCA plus regression approach.
		\begin{itemize}
			\item We must account not only for the coefficient uncertainty but also the contribution to variance of each individual PC.
		\end{itemize}
	\end{itemize}
\end{frame}

\end{document}